"""
–¢—Ä–µ–Ω–µ—Ä –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã: Graph Transformer + ANN
–û–±—É—á–∞–µ—Ç ANN –Ω–∞ –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –≥—Ä–∞—Ñ–æ–≤—ã–º–∏ –ø—Ä–∏–∑–Ω–∞–∫–∞–º–∏
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
import pandas as pd
import os
from datetime import datetime
from typing import List, Dict
from real_distance_analyzer import RealDistanceAnalyzer # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π

class IntegratedRouteDataset(Dataset):
    """
    –î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
    –°–æ–∑–¥–∞–µ—Ç –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ: 7 –∏—Å—Ö–æ–¥–Ω—ã—Ö + 7 –≥—Ä–∞—Ñ–æ–≤—ã—Ö = 14 –ø—Ä–∏–∑–Ω–∞–∫–æ–≤
    """

    def __init__(self, data_dir: str = "DS", use_real_distances: bool = True,
                 tomtom_api_key: str = None):
        self.data_dir = data_dir
        self.use_real_distances = use_real_distances

        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–π
        if use_real_distances:
            self.distance_analyzer = RealDistanceAnalyzer(tomtom_api_key)
            self.distance_analyzer.load_nyc_trip_data()
            self.distance_analyzer.load_zone_geometries()

        self.trips = self._load_nyc_data()

    def _load_nyc_data(self):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ NYC –¥–∞–Ω–Ω—ã—Ö –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–∞—Ä—à—Ä—É—Ç–æ–≤
        """
        try:
            # –ó–∞–≥—Ä—É–∂–∞–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
            combined_data_path = "combined_training_data.csv"

            if os.path.exists(combined_data_path):
                print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è...")
                df = pd.read_csv(combined_data_path)

                trips = []
                for _, row in df.iterrows():
                    trip = {
                        'lat': row.get('latitude', 0.0),
                        'lon': row.get('longitude', 0.0),
                        'is_vip': row.get('is_vip', 0),
                        'work_start_hour': row.get('work_start_hour', 0.0),
                        'work_end_hour': row.get('work_end_hour', 0.0),
                        'lunch_start_hour': row.get('lunch_start_hour', 0.0),
                        'lunch_end_hour': row.get('lunch_end_hour', 0.0)
                    }
                    trips.append(trip)

                print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(trips)} –∑–∞–ø–∏—Å–µ–π –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è")
                return trips
            else:
                print("‚ùå –§–∞–π–ª combined_training_data.csv –Ω–µ –Ω–∞–π–¥–µ–Ω!")
                return []

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return []

    def __len__(self):
        return len(self.trips)

    def __getitem__(self, idx):
        """
        –°–æ–∑–¥–∞–µ—Ç –º–∞—Ä—à—Ä—É—Ç –∏–∑ NYC –¥–∞–Ω–Ω—ã—Ö
        """
        # –ë–µ—Ä–µ–º 5-10 —Å–ª—É—á–∞–π–Ω—ã—Ö –ø–æ–µ–∑–¥–æ–∫ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –º–∞—Ä—à—Ä—É—Ç–∞
        route_size = np.random.randint(5, 11)
        start_idx = idx % (len(self.trips) - route_size)

        route_trips = self.trips[start_idx:start_idx + route_size]

        # –°–æ–∑–¥–∞–µ–º –∫–ª–∏–µ–Ω—Ç–æ–≤
        clients = []
        for i, trip in enumerate(route_trips):
            client = {
                'lat': trip['lat'],
                'lon': trip['lon'],
                'client_level': 'VIP' if trip['is_vip'] == 1 else 'regular',
                'work_start_hour': trip['work_start_hour'],
                'work_end_hour': trip['work_end_hour'],
                'lunch_start_hour': trip['lunch_start_hour'],
                'lunch_end_hour': trip['lunch_end_hour']
            }
            clients.append(client)

        # –°–æ–∑–¥–∞–µ–º –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ (VIP –ø–µ—Ä–≤—ã–π, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—é)
        optimal_order = self._create_optimal_order(clients)

        return {
            'clients': clients,
            'optimal_order': optimal_order,
            'route_id': f"route_{idx}"
        }

    def _create_optimal_order(self, clients: List[Dict]) -> List[int]:
        """
        –°–æ–∑–¥–∞–µ—Ç –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –ø–æ—Å–µ—â–µ–Ω–∏—è –∫–ª–∏–µ–Ω—Ç–æ–≤
        """
        num_clients = len(clients)

        # VIP –∫–ª–∏–µ–Ω—Ç—ã –ø–æ–ª—É—á–∞—é—Ç –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç
        vip_indices = [i for i, client in enumerate(clients) if client['client_level'] == 'VIP']
        regular_indices = [i for i, client in enumerate(clients) if client['client_level'] == 'regular']

        # –ü—Ä–æ—Å—Ç–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞: VIP –ø–µ—Ä–≤—ã–π, –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–æ –±–ª–∏–∂–∞–π—à–µ–º—É —Å–æ—Å–µ–¥—É
        optimal_order = vip_indices.copy()

        if regular_indices:
            # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—ã—á–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ –ø–æ –±–ª–∏–∂–∞–π—à–µ–º—É —Å–æ—Å–µ–¥—É
            current = vip_indices[0] if vip_indices else regular_indices[0]
            remaining = regular_indices.copy()

            while remaining:
                distances = []
                for next_idx in remaining:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º —Ä–µ–∞–ª—å–Ω—ã–µ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è –µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω—ã
                    if self.use_real_distances and hasattr(self, 'distance_analyzer'):
                        dist = self.distance_analyzer.get_rostov_distance(
                            clients[current]['lat'], clients[current]['lon'],
                            clients[next_idx]['lat'], clients[next_idx]['lon']
                        )
                    else:
                        dist = np.sqrt((clients[current]['lat'] - clients[next_idx]['lat'])**2 +
                                     (clients[current]['lon'] - clients[next_idx]['lon'])**2)
                    distances.append((dist, next_idx))

                distances.sort()
                next_client = distances[0][1]
                optimal_order.append(next_client)
                remaining.remove(next_client)
                current = next_client

        return optimal_order

class IntegratedTrainer:
    """
    –¢—Ä–µ–Ω–µ—Ä –¥–ª—è –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
    """

    def __init__(self, ann_model, graph_extractor, device='cpu'):
        self.ann_model = ann_model
        self.graph_extractor = graph_extractor
        self.device = device

        # –ü–µ—Ä–µ–Ω–æ—Å–∏–º –º–æ–¥–µ–ª–∏ –Ω–∞ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ
        self.ann_model.to(device)
        self.graph_extractor.to(device)

    def train_epoch(self, dataloader, optimizer, criterion):
        """
        –û–±—É—á–µ–Ω–∏–µ –æ–¥–Ω–æ–π —ç–ø–æ—Ö–∏ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
        """
        self.ann_model.train()
        self.graph_extractor.train()

        total_loss = 0

        for batch in dataloader:
            clients = batch['clients']
            optimal_order = batch['optimal_order']

            # –≠—Ç–∞–ø 1: Graph Transformer –∏–∑–≤–ª–µ–∫–∞–µ—Ç –≥—Ä–∞—Ñ–æ–≤—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            enriched_features = self.graph_extractor.extract_graph_features(clients)

            # –≠—Ç–∞–ø 2: ANN –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–±–æ–≥–∞—â–µ–Ω–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏
            features_tensor = torch.tensor(enriched_features, dtype=torch.float).to(self.device)

            # ANN –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏–µ
            ann_output = self.ann_model(features_tensor)

            # –°–æ–∑–¥–∞–µ–º —Ü–µ–ª–µ–≤—ã–µ –∑–Ω–∞—á–µ–Ω–∏—è
            target_scores = torch.zeros(len(clients))
            for i, order_idx in enumerate(optimal_order):
                target_scores[order_idx] = len(clients) - i  # –í—ã—Å—à–∏–π –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç = –±–æ–ª—å—à–µ–µ —á–∏—Å–ª–æ

            target_scores = target_scores.to(self.device)

            # –í—ã—á–∏—Å–ª—è–µ–º loss
            loss = criterion(ann_output.squeeze(), target_scores)

            # Backward pass
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()

            total_loss += loss.item()

        return total_loss / len(dataloader)

    def train(self, train_data: List[Dict], epochs: int = 100,
              batch_size: int = 4, learning_rate: float = 0.001,
              save_path: str = 'integrated_model.pth'):
        """
        –ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
        """
        print(f"üß† –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã...")
        print(f"üìä –î–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è: {len(train_data)}")
        print(f"üéØ –≠–ø–æ—Ö: {epochs}")
        print(f"üì¶ Batch size: {batch_size}")
        print(f"üìà Learning rate: {learning_rate}")

        # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä
        dataset = IntegratedRouteDataset()
        dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)

        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ loss —Ñ—É–Ω–∫—Ü–∏—è
        optimizer = optim.Adam(self.ann_model.parameters(), lr=learning_rate)
        criterion = nn.MSELoss()

        # –ò—Å—Ç–æ—Ä–∏—è –æ–±—É—á–µ–Ω–∏—è
        train_losses = []

        print(f"\nüöÄ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã...")

        for epoch in range(epochs):
            # –û–±—É—á–µ–Ω–∏–µ
            train_loss = self.train_epoch(dataloader, optimizer, criterion)
            train_losses.append(train_loss)

            # –í—ã–≤–æ–¥–∏–º –ø—Ä–æ–≥—Ä–µ—Å—Å
            if epoch % 10 == 0 or epoch == epochs - 1:
                print(f"–≠–ø–æ—Ö–∞ {epoch+1}/{epochs}, Loss: {train_loss:.6f}")

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–æ–¥–µ–ª—å
        torch.save(self.ann_model.state_dict(), save_path)
        print(f"\n‚úÖ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"üíæ ANN –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {save_path}")
        print(f"üìâ –§–∏–Ω–∞–ª—å–Ω—ã–π loss: {train_losses[-1]:.6f}")

        return {
            'status': 'success',
            'epochs_trained': epochs,
            'final_loss': train_losses[-1],
            'train_losses': train_losses,
            'model_saved': save_path
        }

def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–π —Å–∏—Å—Ç–µ–º—ã
    """
    print("üß† Integrated System Trainer")
    print("=" * 50)

    # –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –º–æ–¥–µ–ª–∏
    from tomtom_traffic_router import GraphTransformerFeatureExtractor
    from train_model import AttentionRouteOptimizer

    # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª–∏
    graph_extractor = GraphTransformerFeatureExtractor(
        input_dim=7,
        hidden_dim=128,
        num_heads=8,
        num_layers=2,
        dropout=0.1
    )

    ann_model = AttentionRouteOptimizer(
        input_dim=14,  # 7 –∏—Å—Ö–æ–¥–Ω—ã—Ö + 7 –≥—Ä–∞—Ñ–æ–≤—ã—Ö
        hidden_dim=256,
        num_heads=8,
        num_layers=3
    )

    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä
    trainer = IntegratedTrainer(ann_model, graph_extractor)

    # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è —Å —Ä–µ–∞–ª—å–Ω—ã–º–∏ —Ä–∞—Å—Å—Ç–æ—è–Ω–∏—è–º–∏
    dataset = IntegratedRouteDataset(
        use_real_distances=True,
        tomtom_api_key="zq6uGYYW806zBrLssIilztKU6ixjAOkr"
    )
    training_data = [dataset[i] for i in range(min(100, len(dataset)))]  # 100 –ø—Ä–∏–º–µ—Ä–æ–≤

    if not training_data:
        print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è!")
        return

    # –û–±—É—á–∞–µ–º –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É
    result = trainer.train(
        train_data=training_data,
        epochs=50,
        batch_size=2,
        learning_rate=0.001,
        save_path='integrated_model.pth'
    )

    if result['status'] == 'success':
        print(f"\nüéâ –ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"üìä –≠–ø–æ—Ö –æ–±—É—á–µ–Ω–æ: {result['epochs_trained']}")
        print(f"üìâ –§–∏–Ω–∞–ª—å–Ω—ã–π loss: {result['final_loss']:.6f}")
        print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {result['model_saved']}")
        print(f"\nüöÄ –¢–µ–ø–µ—Ä—å –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É!")
    else:
        print(f"‚ùå –û—à–∏–±–∫–∞ –æ–±—É—á–µ–Ω–∏—è: {result.get('message', '–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –æ—à–∏–±–∫–∞')}")

if __name__ == "__main__":
    main()
