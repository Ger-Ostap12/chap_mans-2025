"""
–û–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ NYC
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç Attention-based Neural Network –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–∞—Ä—à—Ä—É—Ç–æ–≤
"""

import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
import numpy as np
import pandas as pd
import os
import json
from datetime import datetime
import sys

class RouteOptimizationDataset(Dataset):
    """
    –î–∞—Ç–∞—Å–µ—Ç –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–∞—Ä—à—Ä—É—Ç–æ–≤ –Ω–∞ NYC –¥–∞–Ω–Ω—ã—Ö
    """

    def __init__(self, data_dir: str = "DS"):
        self.data_dir = data_dir
        self.trips = self._load_nyc_data()

    def _load_nyc_data(self):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (NYC + —Å–∏–Ω—Ç–µ—Ç–∏—á–µ—Å–∫–∏–µ –≤—Ä–µ–º–µ–Ω–∞)
        """
        # –°–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        combined_data_path = "combined_training_data.csv"

        if os.path.exists(combined_data_path):
            print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö (NYC + –≤—Ä–µ–º–µ–Ω–∞)...")
            return self._load_combined_data(combined_data_path)
        else:
            print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–ª—å–∫–æ NYC –¥–∞–Ω–Ω—ã—Ö (–±–µ–∑ –≤—Ä–µ–º–µ–Ω–Ω—ã—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)...")
            return self._load_nyc_only_data()

    def _load_combined_data(self, data_path: str):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏
        """
        try:
            df = pd.read_csv(data_path)
            print(f"üìã –ö–æ–ª–æ–Ω–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö: {list(df.columns)}")

            trips = []
            for _, row in df.iterrows():
                trip = {
                    'latitude': float(row['latitude']),
                    'longitude': float(row['longitude']),
                    'is_vip': bool(row['is_vip']),
                    'work_start_hour': float(row['work_start_hour']),
                    'work_end_hour': float(row['work_end_hour']),
                    'lunch_start_hour': float(row['lunch_start_hour']),
                    'lunch_end_hour': float(row['lunch_end_hour']),
                    'timestamp': np.random.randint(0, 86400),
                    'distance': 1.0,
                    'time': 30.0,
                    'fare': 10.0
                }
                trips.append(trip)

            print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(trips)} –∑–∞–ø–∏—Å–µ–π —Å –≤—Ä–µ–º–µ–Ω–Ω—ã–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏")
            return trips

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –æ–±—ä–µ–¥–∏–Ω–µ–Ω–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö: {e}")
            return self._load_nyc_only_data()

    def _load_nyc_only_data(self):
        """
        –ó–∞–≥—Ä—É–∑–∫–∞ —Ç–æ–ª—å–∫–æ NYC –¥–∞–Ω–Ω—ã—Ö (—Å—Ç–∞—Ä—ã–π –º–µ—Ç–æ–¥)
        """
        trip_data_path = os.path.join(self.data_dir, "taxi_trip_data.csv")

        if not os.path.exists(trip_data_path):
            print(f"‚ùå –§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {trip_data_path}")
            return []

        print("üìä –ó–∞–≥—Ä—É–∑–∫–∞ NYC –¥–∞–Ω–Ω—ã—Ö...")

        # –ß–∏—Ç–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ—Ä—Ü–∏—è–º–∏ –¥–ª—è —ç–∫–æ–Ω–æ–º–∏–∏ –ø–∞–º—è—Ç–∏
        trips = []
        chunk_size = 10000  # –£–º–µ–Ω—å—à–∞–µ–º —Ä–∞–∑–º–µ—Ä —á–∞–Ω–∫–∞

        try:
            for chunk in pd.read_csv(trip_data_path, chunksize=chunk_size):
                # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–∞–Ω–Ω—ã—Ö
                if len(trips) == 0:
                    print(f"üìã –ö–æ–ª–æ–Ω–∫–∏ –≤ –¥–∞–Ω–Ω—ã—Ö: {list(chunk.columns)}")

                # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ –Ω–µ—Å–∫–æ–ª—å–∫–æ —á–∞–Ω–∫–æ–≤ –¥–ª—è –æ–±—É—á–µ–Ω–∏—è
                if len(trips) >= 50000:  # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –¥–æ 50k –ø–æ–µ–∑–¥–æ–∫
                    break

                # –ò—Å–ø–æ–ª—å–∑—É–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ NYC —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                for _, row in chunk.iterrows():
                    try:
                        # –ò–∑–≤–ª–µ–∫–∞–µ–º –¥–∞–Ω–Ω—ã–µ –∏–∑ NYC —Å—Ç—Ä—É–∫—Ç—É—Ä—ã
                        pickup_location = row.get('pickup_location_id', None)
                        dropoff_location = row.get('dropoff_location_id', None)
                        trip_distance = row.get('trip_distance', 0)
                        fare_amount = row.get('fare_amount', 0)

                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤–∞–ª–∏–¥–Ω–æ—Å—Ç—å –¥–∞–Ω–Ω—ã—Ö
                        if (pd.notna(pickup_location) and pd.notna(dropoff_location) and
                            pickup_location > 0 and dropoff_location > 0):

                            # –°–æ–∑–¥–∞–µ–º –ø–æ–µ–∑–¥–∫—É —Å –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç–∞–º–∏ –∏–∑ –∑–æ–Ω
                            # –ò—Å–ø–æ–ª—å–∑—É–µ–º ID –∑–æ–Ω –∫–∞–∫ –∫–æ–æ—Ä–¥–∏–Ω–∞—Ç—ã (—É–ø—Ä–æ—â–µ–Ω–∏–µ)
                            trip = {
                                'latitude': pickup_location / 1000.0,  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º ID –∑–æ–Ω—ã
                                'longitude': dropoff_location / 1000.0,  # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º ID –∑–æ–Ω—ã
                                'is_vip': np.random.choice([True, False]),  # –°–ª—É—á–∞–π–Ω—ã–π VIP
                                'work_start_hour': 0.33,  # 08:00 –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ
                                'work_end_hour': 0.75,   # 18:00 –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ
                                'lunch_start_hour': 0.54, # 13:00 –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ
                                'lunch_end_hour': 0.58,   # 14:00 –Ω–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞–Ω–Ω–æ–µ
                                'timestamp': np.random.randint(0, 86400),  # —Å–ª—É—á–∞–π–Ω–æ–µ –≤—Ä–µ–º—è
                                'distance': float(trip_distance) if pd.notna(trip_distance) else 1.0,
                                'time': np.random.uniform(5, 120),  # —Å–ª—É—á–∞–π–Ω–æ–µ –≤—Ä–µ–º—è –ø–æ–µ–∑–¥–∫–∏
                                'fare': float(fare_amount) if pd.notna(fare_amount) else 10.0
                            }
                            trips.append(trip)

                    except Exception as e:
                        continue

                print(f"üìä –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ {len(trips)} –ø–æ–µ–∑–¥–æ–∫...")

        except Exception as e:
            print(f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö: {e}")
            return []

        print(f"‚úÖ –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(trips)} –ø–æ–µ–∑–¥–æ–∫ –∏–∑ NYC")
        return trips

    def __len__(self):
        return len(self.trips)

    def __getitem__(self, idx):
        """
        –ü–æ–ª—É—á–µ–Ω–∏–µ –æ–¥–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ –¥–∞—Ç–∞—Å–µ—Ç–∞
        """
        # –°–æ–∑–¥–∞–µ–º –≥—Ä—É–ø–ø—É –∏–∑ 8 —Å–ª—É—á–∞–π–Ω—ã—Ö –ø–æ–µ–∑–¥–æ–∫ –¥–ª—è –∑–∞–¥–∞—á–∏ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏
        group_size = 8
        start_idx = (idx * group_size) % len(self.trips)

        # –ë–µ—Ä–µ–º –≥—Ä—É–ø–ø—É –ø–æ–µ–∑–¥–æ–∫
        group_trips = []
        for i in range(group_size):
            trip_idx = (start_idx + i) % len(self.trips)
            group_trips.append(self.trips[trip_idx])

        # –ü–æ–¥–≥–æ—Ç–∞–≤–ª–∏–≤–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –º–æ–¥–µ–ª–∏
        features = self._prepare_features(group_trips)
        targets = self._prepare_targets(group_trips)

        return {
            'features': torch.FloatTensor(features),
            'targets': torch.LongTensor(targets),
            'trip_group_id': f"group_{idx}"
        }

    def _prepare_features(self, trips):
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ –ø—Ä–∏–∑–Ω–∞–∫–æ–≤ –¥–ª—è –º–æ–¥–µ–ª–∏ (7 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
        """
        features = []

        for trip in trips:
            # –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–∑–Ω–∞–∫–∏ –ø–æ–µ–∑–¥–∫–∏ (7 –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤)
            trip_features = [
                trip['latitude'],
                trip['longitude'],
                float(trip['is_vip']),
                trip['work_start_hour'],
                trip['work_end_hour'],
                trip['lunch_start_hour'],
                trip['lunch_end_hour']
            ]

            features.append(trip_features)

        return np.array(features)

    def _prepare_targets(self, trips):
        """
        –ü–æ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ü–µ–ª–µ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏–π (–æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –ø–æ—Ä—è–¥–æ–∫ –ø–æ—Å–µ—â–µ–Ω–∏—è)
        """
        # –°–æ–∑–¥–∞–µ–º –ø—Ä–æ—Å—Ç–æ–π –æ–ø—Ç–∏–º–∞–ª—å–Ω—ã–π –º–∞—Ä—à—Ä—É—Ç (–±–ª–∏–∂–∞–π—à–∏–π —Å–æ—Å–µ–¥)
        targets = [0] * len(trips)
        visited = [False] * len(trips)
        current = 0
        visited[0] = True

        for step in range(1, len(trips)):
            min_distance = float('inf')
            nearest = 0

            for i in range(len(trips)):
                if not visited[i]:
                    # –í—ã—á–∏—Å–ª—è–µ–º —Ä–∞—Å—Å—Ç–æ—è–Ω–∏–µ
                    dist = np.sqrt(
                        (trips[current]['latitude'] - trips[i]['latitude'])**2 +
                        (trips[current]['longitude'] - trips[i]['longitude'])**2
                    )

                    if dist < min_distance:
                        min_distance = dist
                        nearest = i

            targets[nearest] = step
            visited[nearest] = True
            current = nearest

        return targets

class AttentionRouteOptimizer(nn.Module):
    """
    Attention-based Neural Network –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –º–∞—Ä—à—Ä—É—Ç–æ–≤
    """

    def __init__(self, input_dim: int = 7, hidden_dim: int = 256, num_heads: int = 8, num_layers: int = 3):
        super().__init__()

        self.hidden_dim = hidden_dim
        self.num_heads = num_heads

        # –í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
        self.input_layer = nn.Linear(input_dim, hidden_dim)

        # Attention —Å–ª–æ–∏
        self.attention_layers = nn.ModuleList([
            nn.MultiheadAttention(hidden_dim, num_heads, batch_first=True)
            for _ in range(num_layers)
        ])

        # –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è
        self.norm_layers = nn.ModuleList([
            nn.LayerNorm(hidden_dim)
            for _ in range(num_layers)
        ])

        # –í—ã—Ö–æ–¥–Ω—ã–µ —Å–ª–æ–∏
        self.route_output = nn.Linear(hidden_dim, 1)
        self.time_output = nn.Linear(hidden_dim, 1)
        self.priority_output = nn.Linear(hidden_dim, 1)

        # –ê–∫—Ç–∏–≤–∞—Ü–∏—è
        self.activation = nn.ReLU()

    def forward(self, x, mask=None):
        """
        –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥ –º–æ–¥–µ–ª–∏
        """
        batch_size, seq_len, _ = x.shape

        # –í—Ö–æ–¥–Ω–æ–π —Å–ª–æ–π
        x = self.input_layer(x)

        # Attention —Å–ª–æ–∏
        for attention, norm in zip(self.attention_layers, self.norm_layers):
            # Self-attention
            attn_output, _ = attention(x, x, x, key_padding_mask=mask)
            x = norm(x + attn_output)
            x = self.activation(x)

        # –í—ã—Ö–æ–¥–Ω—ã–µ –ø—Ä–µ–¥—Å–∫–∞–∑–∞–Ω–∏—è
        route_scores = self.route_output(x)
        time_predictions = self.time_output(x)
        priority_scores = self.priority_output(x)

        return {
            'route_scores': route_scores.squeeze(-1),
            'time_predictions': time_predictions.squeeze(-1),
            'priority_scores': priority_scores.squeeze(-1)
        }

class ModelTrainer:
    """
    –¢—Ä–µ–Ω–µ—Ä –¥–ª—è –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏
    """

    def __init__(self, data_dir: str = "DS"):
        self.data_dir = data_dir
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        # –°–æ–∑–¥–∞–µ–º –º–æ–¥–µ–ª—å
        self.model = AttentionRouteOptimizer().to(self.device)

        # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä –∏ —Ñ—É–Ω–∫—Ü–∏—è –ø–æ—Ç–µ—Ä—å
        self.optimizer = optim.Adam(self.model.parameters(), lr=0.001)
        self.criterion = nn.MSELoss()  # –ò—Å–ø–æ–ª—å–∑—É–µ–º MSE –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏

        print(f"üñ•Ô∏è  –£—Å—Ç—Ä–æ–π—Å—Ç–≤–æ: {self.device}")
        print(f"üß† –ú–æ–¥–µ–ª—å: {sum(p.numel() for p in self.model.parameters())} –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")

    def train_epoch(self, dataloader):
        """
        –û–±—É—á–µ–Ω–∏–µ –æ–¥–Ω–æ–π —ç–ø–æ—Ö–∏
        """
        self.model.train()
        total_loss = 0

        for batch in dataloader:
            features = batch['features'].to(self.device)
            targets = batch['targets'].to(self.device)

            # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É –¥–ª—è padding
            batch_size, seq_len = features.shape[:2]
            mask = torch.zeros(batch_size, seq_len, dtype=torch.bool, device=self.device)

            # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥
            outputs = self.model(features, mask)

            # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ—Ç–µ—Ä–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º route_scores –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏)
            # –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º targets –≤ float –¥–ª—è MSE
            targets_float = targets.float()
            loss = self.criterion(outputs['route_scores'], targets_float)

            # –û–±—Ä–∞—Ç–Ω–æ–µ —Ä–∞—Å–ø—Ä–æ—Å—Ç—Ä–∞–Ω–µ–Ω–∏–µ
            self.optimizer.zero_grad()
            loss.backward()
            self.optimizer.step()

            total_loss += loss.item()

        return total_loss / len(dataloader)

    def validate(self, dataloader):
        """
        –í–∞–ª–∏–¥–∞—Ü–∏—è –º–æ–¥–µ–ª–∏
        """
        self.model.eval()
        total_loss = 0

        with torch.no_grad():
            for batch in dataloader:
                features = batch['features'].to(self.device)
                targets = batch['targets'].to(self.device)

                # –°–æ–∑–¥–∞–µ–º –º–∞—Å–∫—É
                batch_size, seq_len = features.shape[:2]
                mask = torch.zeros(batch_size, seq_len, dtype=torch.bool, device=self.device)

                # –ü—Ä—è–º–æ–π –ø—Ä–æ—Ö–æ–¥
                outputs = self.model(features, mask)

                # –í—ã—á–∏—Å–ª—è–µ–º –ø–æ—Ç–µ—Ä–∏ (–∏—Å–ø–æ–ª—å–∑—É–µ–º route_scores –¥–ª—è —Ä–µ–≥—Ä–µ—Å—Å–∏–∏)
                targets_float = targets.float()
                loss = self.criterion(outputs['route_scores'], targets_float)
                total_loss += loss.item()

        return total_loss / len(dataloader)

    def train(self, num_epochs: int = 50, start_epoch: int = 0):
        """
        –ü–æ–ª–Ω–æ–µ –æ–±—É—á–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏
        """
        print("üöÄ –ù–∞—á–∞–ª–æ –æ–±—É—á–µ–Ω–∏—è –º–æ–¥–µ–ª–∏...")

        # –°–æ–∑–¥–∞–µ–º –¥–∞—Ç–∞—Å–µ—Ç –∏ –¥–∞—Ç–∞–ª–æ–∞–¥–µ—Ä
        dataset = RouteOptimizationDataset(self.data_dir)

        if len(dataset) == 0:
            print("‚ùå –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –æ–±—É—á–µ–Ω–∏—è")
            return False

        # –†–∞–∑–¥–µ–ª—è–µ–º –Ω–∞ train/val
        train_size = int(0.8 * len(dataset))
        val_size = len(dataset) - train_size
        train_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])

        train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)

        print(f"üìä Train: {len(train_dataset)}, Val: {len(val_dataset)}")

        # –ü—ã—Ç–∞–µ–º—Å—è –∑–∞–≥—Ä—É–∑–∏—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å
        best_val_loss = float('inf')
        if os.path.exists("best_model.pth"):
            print("üìÅ –ó–∞–≥—Ä—É–∂–∞–µ–º —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –º–æ–¥–µ–ª—å...")
            try:
                checkpoint = torch.load("best_model.pth", map_location=self.device)
                self.model.load_state_dict(checkpoint)
                print("‚úÖ –ú–æ–¥–µ–ª—å –∑–∞–≥—Ä—É–∂–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ")
            except Exception as e:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –∑–∞–≥—Ä—É–∑–∫–∏ –º–æ–¥–µ–ª–∏: {e}")
                print("üîÑ –ù–∞—á–∏–Ω–∞–µ–º –æ–±—É—á–µ–Ω–∏–µ —Å –Ω—É–ª—è")

        # –û–±—É—á–µ–Ω–∏–µ
        patience = 10
        patience_counter = 0

        for epoch in range(start_epoch, num_epochs):
            # –û–±—É—á–µ–Ω–∏–µ
            train_loss = self.train_epoch(train_loader)

            # –í–∞–ª–∏–¥–∞—Ü–∏—è
            val_loss = self.validate(val_loader)

            print(f"–≠–ø–æ—Ö–∞ {epoch+1}/{num_epochs}: Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}")

            # Early stopping
            if val_loss < best_val_loss:
                best_val_loss = val_loss
                patience_counter = 0
                # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å
                torch.save(self.model.state_dict(), "best_model.pth")
            else:
                patience_counter += 1
                if patience_counter >= patience:
                    print(f"üõë Early stopping –Ω–∞ —ç–ø–æ—Ö–µ {epoch+1}")
                    break

        print("‚úÖ –û–±—É—á–µ–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"üìÅ –õ—É—á—à–∞—è –º–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: best_model.pth")

        return True

    def save_model(self, path: str = "trained_model.pth"):
        """
        –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –æ–±—É—á–µ–Ω–Ω–æ–π –º–æ–¥–µ–ª–∏
        """
        torch.save({
            'model_state_dict': self.model.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'model_config': {
                'input_dim': 7,
                'hidden_dim': 256,
                'num_heads': 8,
                'num_layers': 3
            }
        }, path)

        print(f"üíæ –ú–æ–¥–µ–ª—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞: {path}")

def main():
    """
    –û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–±—É—á–µ–Ω–∏—è
    """
    print("üéØ –û–±—É—á–µ–Ω–∏–µ ML –º–æ–¥–µ–ª–∏ –Ω–∞ –¥–∞–Ω–Ω—ã—Ö –∏–∑ NYC")
    print("=" * 60)

    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –¥–∞–Ω–Ω—ã—Ö
    data_dir = "DS"
    trip_file = os.path.join(data_dir, "taxi_trip_data.csv")

    if not os.path.exists(trip_file):
        print(f"‚ùå –§–∞–π–ª –¥–∞–Ω–Ω—ã—Ö –Ω–µ –Ω–∞–π–¥–µ–Ω: {trip_file}")
        print("üí° –£–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —Ñ–∞–π–ª—ã NYC –¥–∞–Ω–Ω—ã—Ö –Ω–∞—Ö–æ–¥—è—Ç—Å—è –≤ –ø–∞–ø–∫–µ DS/")
        return

    # –°–æ–∑–¥–∞–µ–º —Ç—Ä–µ–Ω–µ—Ä
    trainer = ModelTrainer(data_dir)

    # –û–±—É—á–∞–µ–º –º–æ–¥–µ–ª—å (–ø—Ä–æ–¥–æ–ª–∂–∞–µ–º —Å 25-–π —ç–ø–æ—Ö–∏ –¥–æ 30-–π)
    success = trainer.train(num_epochs=30, start_epoch=25)

    if success:
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ñ–∏–Ω–∞–ª—å–Ω—É—é –º–æ–¥–µ–ª—å
        trainer.save_model("trained_model.pth")

        print("\nüéâ –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
        print("üìÅ –§–∞–π–ª—ã –º–æ–¥–µ–ª–∏:")
        print("- best_model.pth (–ª—É—á—à–∞—è –º–æ–¥–µ–ª—å)")
        print("- trained_model.pth (—Ñ–∏–Ω–∞–ª—å–Ω–∞—è –º–æ–¥–µ–ª—å)")
        print("\nüìã –°–ª–µ–¥—É—é—â–∏–µ —à–∞–≥–∏:")
        print("1. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ –æ–±—É—á–µ–Ω–Ω—É—é –º–æ–¥–µ–ª—å –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –º–∞—Ä—à—Ä—É—Ç–æ–≤")
        print("2. –ú–æ–¥–µ–ª—å –≥–æ—Ç–æ–≤–∞ –∫ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–∏ –≤ –≤–∞—à–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ")
        print("\nüí° –ú–æ–¥–µ–ª—å –æ–±—É—á–µ–Ω–∞ –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã—Ö –¥–∞–Ω–Ω—ã—Ö –∏–∑ NYC!")
    else:
        print("\n‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—É—á–µ–Ω–∏–∏ –º–æ–¥–µ–ª–∏")

if __name__ == "__main__":
    main()
